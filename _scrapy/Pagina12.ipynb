{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "\n",
    "class Spider12(scrapy.Spider):\n",
    "    name = \"Spider12\"\n",
    "    # Dominios a permitir\n",
    "    allowed_domains = [\"pagina12.com.ar\"]\n",
    "    # Configraciones\n",
    "    custom_settings = {\"FEED_FORMAT\": \"json\", \"FEED_URI\": \"resultados.json\", \"DEPTH_LIMIT\": 2,\n",
    "                       \"FEED_EXPORT_ENCODING\": \"utf-8\", }\n",
    "    # URLs a crawlear\n",
    "    start_urls = ['https://www.pagina12.com.ar/secciones/el-pais',\n",
    "                  'https://www.pagina12.com.ar/secciones/economia',\n",
    "                  'https://www.pagina12.com.ar/secciones/sociedad',\n",
    "                  'https://www.pagina12.com.ar/suplementos/cultura-y-espectaculos',\n",
    "                  'https://www.pagina12.com.ar/secciones/el-mundo',\n",
    "                  'https://www.pagina12.com.ar/secciones/deportes',\n",
    "                  'https://www.pagina12.com.ar/secciones/cultura',\n",
    "                  'https://www.pagina12.com.ar/secciones/contratapa']\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Articulo promocionado\n",
    "        nota_promocionada = response.xpath(\"//div[@class='featured-article__container']/h2/a/@href\").get()\n",
    "        if nota_promocionada is not None:\n",
    "            # follow => se le indica que funcion debe continuar con la estraccion de la data\n",
    "            yield response.follow(nota_promocionada, call_back=self.parse_nota)\n",
    "\n",
    "        # Lista de noticias\n",
    "        noticias = response.xpath(\"//ul[@class='article-list']//li//a/@href\").getall()\n",
    "        for noticia in noticias:\n",
    "            yield response.follow(noticia, callback=self.parse_nota)\n",
    "\n",
    "        # Link a la siguiente p√°gina\n",
    "        next_page = response.xpath(\"//a[@class='pagination-btn-next']/@href\")\n",
    "        if next_page is not None:\n",
    "            # Para este caso le indica que sea recursivo al llamar la misma funcion\n",
    "            yield response.follow(next_page, callback=self.parse)\n",
    "\n",
    "    def parse_nota(self, response):\n",
    "        titulo = response.xpath(\"//div[@class='article-title']/text()\").get()\n",
    "        cuerpo = \"\".join(response.xpath(\"//div[@class='article-text']/p/text()\").getall())\n",
    "        # Una ves se extrae la data, se retorna el json, que se pusheara\n",
    "        yield {\"url\": response.url, \"titulo\": titulo, \"cuerpo\": cuerpo}\n",
    "\n",
    "# Inicia el proceso de crawling\n",
    "process = CrawlerProcess()\n",
    "# Se le pasa la clase con las configuraciones\n",
    "process.crawl(Spider12)\n",
    "# Inicia el proces\n",
    "# Es mejor verlo por consola que con el notbbook\n",
    "process.start"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}